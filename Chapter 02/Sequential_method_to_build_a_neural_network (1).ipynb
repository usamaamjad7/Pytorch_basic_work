{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sequential_method_to_build_a_neural_network.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMWUpEVIZRJDP3GtrL9/pm5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ykKQ1aLB3STB"},"source":["# **Using a Sequential method to build a neural network..**"]},{"cell_type":"markdown","metadata":{"id":"BAFiv5e13tgE"},"source":["So far, we have built a neural network by defining a class where we define the layers and how the layers are connected with each other. In this section, we will learn about a simplified way of defining the neural network architecture using the Sequential class. We will perform the same steps as we have done in the previous sections, except that the class that was used to define the neural network architecture manually will be substituted with a Sequential class for creating a neural network architecture."]},{"cell_type":"markdown","metadata":{"id":"FWygr27t31-J"},"source":["# **Define the toy dataset:**"]},{"cell_type":"code","metadata":{"id":"Nv7IftM-3P71","executionInfo":{"status":"ok","timestamp":1621851409518,"user_tz":-300,"elapsed":8,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["x =  [[1,2],[3,4],[5,6],[7,8]]\n","y = [[3],[7],[11],[15]]"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tdx070kA4RRV"},"source":["# Import the relevant packages and define the device we will work on.."]},{"cell_type":"code","metadata":{"id":"E388l4aK4GRo","executionInfo":{"status":"ok","timestamp":1621851621244,"user_tz":-300,"elapsed":368,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from torch.utils.data import Dataset,DataLoader\n","device = 'cuda'if torch.cuda.is_available() else 'gpu'"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N-xQQgr14_7b"},"source":["# Now, we define the dataset class (MyDataset):"]},{"cell_type":"code","metadata":{"id":"xxedjok842f1","executionInfo":{"status":"ok","timestamp":1621851878340,"user_tz":-300,"elapsed":406,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["class MyDataset(Dataset):\n","    def __init__(self,x,y):\n","        self.x = torch.tensor(x).float().to(device)\n","        self.y = torch.tensor(y).float().to(device)\n","\n","    def __getitem__(self,ix):\n","        return self.x[ix],self.y[ix]\n","\n","    def __len__(self):\n","        return len(self.x)\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uJij-wVt5-OV"},"source":["# Define the dataset (ds) and dataloader (dl) object:"]},{"cell_type":"code","metadata":{"id":"Vm4kJ67e563M","executionInfo":{"status":"ok","timestamp":1621852033571,"user_tz":-300,"elapsed":11145,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["ds = MyDataset(x,y)\n","dl = DataLoader(ds,batch_size=2,shuffle=True)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4662dGjf6lcO"},"source":["# Define the model architecture using the Sequential method available in the nn package:"]},{"cell_type":"code","metadata":{"id":"IOSGPQHk6R0H","executionInfo":{"status":"ok","timestamp":1621853419793,"user_tz":-300,"elapsed":402,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["model = nn.Sequential(\n","    nn.Linear(2, 8),\n","    nn.ReLU(),\n","    nn.Linear(8, 1)\n",").to(device)"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DOB6gYyn71ed"},"source":["Note that, in the preceding code, we defined the same architecture of the network as we defined in previous sections, but defined differently. nn.Linear accepts two-dimensional input and gives an eight-dimensional output for each data point. Furthermore, nn.ReLU performs ReLU activation on top of the eight-dimensional output and finally, the eight-dimensional input gives a one-dimensional output (which in our case is the output of the addition of the two inputs) using the final nn.Linear layer."]},{"cell_type":"markdown","metadata":{"id":"CEuyvyVd8Bon"},"source":["# Install and import the package that enables us to print the model summary:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MJO888Ec649M","executionInfo":{"status":"ok","timestamp":1621853425055,"user_tz":-300,"elapsed":2670,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"1072ace9-86f1-47ef-ad39-21183a7fa22a"},"source":["!pip install torch_summary\n","from torchsummary import summary"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch_summary in /usr/local/lib/python3.7/dist-packages (1.4.5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CKX2qApi8YA3"},"source":["# Print a summary of the model, which expects the name of the model and also the input size of the model:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTV6BeTZ8NWn","executionInfo":{"status":"ok","timestamp":1621853427219,"user_tz":-300,"elapsed":386,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"259fa948-6a3e-4dde-9fe5-324af6a87e90"},"source":["summary(model, torch.zeros(1,2));"],"execution_count":25,"outputs":[{"output_type":"stream","text":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","├─Linear: 1-1                            [-1, 8]                   24\n","├─ReLU: 1-2                              [-1, 8]                   --\n","├─Linear: 1-3                            [-1, 1]                   9\n","==========================================================================================\n","Total params: 33\n","Trainable params: 33\n","Non-trainable params: 0\n","Total mult-adds (M): 0.00\n","==========================================================================================\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.00\n","Estimated Total Size (MB): 0.00\n","==========================================================================================\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CXIDqJI3ARkY"},"source":["## Note that the output shape of the first layer is (-1, 8), where -1 represents that there can be as many data points as the batch size, and 8 represents that for each data point, we have an eight-dimensional output resulting in an output of the shape batch size x 8. The interpretation for the next two layers is similar."]},{"cell_type":"markdown","metadata":{"id":"4SwQVoqfAZ7k"},"source":["# Next, we define the loss function (loss_func) and optimizer (opt) and train the model, just like we did in the previous section. Note that, in this case, we need not define a model object; a network is not defined within a class in this scenario:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8FnPBT0L8l73","executionInfo":{"status":"ok","timestamp":1621853970174,"user_tz":-300,"elapsed":380,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"777df3ad-ce01-4659-8e3b-faad8d7d7ed8"},"source":["loss_func = nn.MSELoss()\n","from torch.optim import SGD\n","opt = SGD(model.parameters(),lr=0.001)\n","import time\n","loss_history = []\n","start =time.time()\n","for _ in range(50):\n","    for ix,iy in dl:\n","        opt.zero_grad()\n","        loss_value = loss_func(model(ix),iy)\n","        loss_value.backward()\n","        opt.step()\n","        loss_history.append(loss_value)\n","\n","end = time.time()\n","print(end-start)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["0.19577646255493164\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"t7BwFjKRF_8o"},"source":["# Now that we have trained the model, we can predict values on a validation dataset that we define now:"]},{"cell_type":"markdown","metadata":{"id":"X3xLUWC3GITG"},"source":["# Define the validation dataset:"]},{"cell_type":"code","metadata":{"id":"vmd7jLeqB5BS","executionInfo":{"status":"ok","timestamp":1621855139641,"user_tz":-300,"elapsed":1039,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["val = [[8,9],[10,11],[1.5,2.5]]"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AXXg-OJUGnXR"},"source":["Predict the output of passing the validation list through the model (note that the expected value is the summation of the two inputs for each list within the list of lists). As defined in the dataset class, we first convert the list of lists into a float after converting them into a tensor object and registering them to the device:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SAOxjwokGXDC","executionInfo":{"status":"ok","timestamp":1621855224839,"user_tz":-300,"elapsed":572,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"d264faeb-0430-42a7-ef11-6fe215983ffd"},"source":["model(torch.tensor(val).float().to(device))"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[16.4989],\n","        [20.1449],\n","        [ 4.6493]], device='cuda:0', grad_fn=<AddmmBackward>)"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"SZMDemAMHMlV"},"source":["Now that we have learned about leveraging the sequential method to define and train a model"]},{"cell_type":"code","metadata":{"id":"49ZzsY3IGr9_"},"source":[""],"execution_count":null,"outputs":[]}]}