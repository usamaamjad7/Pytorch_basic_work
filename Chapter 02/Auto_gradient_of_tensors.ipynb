{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Auto_gradient_of_tensors.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPTWtP4oKiF9nsfl/FAdb7j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Y6GlubfiBITe"},"source":["# **Auto gradients of tensor objects**"]},{"cell_type":"markdown","metadata":{"id":"Vln1kY34BPcT"},"source":["As we saw in the previous chapter, differentiation and calculating gradients play a critical role in updating the weights of a neural network. PyTorch's tensor objects come with built-in functionality to calculate gradients.\n","\n","\n","*   In this section, we will understand how to calculate the gradients of a tensor object using PyTorch: \n","\n"]},{"cell_type":"markdown","metadata":{"id":"dJVrEu7YBe2v"},"source":["# Define a Tensor object and also specify how to calculate gradient to be calculated"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1_cXVK98AjDo","executionInfo":{"status":"ok","timestamp":1621753522756,"user_tz":-300,"elapsed":21,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"c8228024-dd3a-4a41-fd38-9f9313fb8bee"},"source":["import numpy as np\n","import torch\n","x = torch.tensor([[2.,-1.],[1.,1.]],requires_grad=True)\n","print(x)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["tensor([[ 2., -1.],\n","        [ 1.,  1.]], requires_grad=True)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3aTBi3LvC22W"},"source":["requires_grad parameter specifies that the gradient is to be calculated on tensor object"]},{"cell_type":"markdown","metadata":{"id":"zKWDYa3ODVX-"},"source":["# Next, define the way to calculate the output, which in this specific case is the sum of the squares of all inputs:"]},{"cell_type":"code","metadata":{"id":"dKV1nmSkCG_m","executionInfo":{"status":"ok","timestamp":1621753763993,"user_tz":-300,"elapsed":5166,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["out = x.pow(2).sum()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-1VIPfBsDyL_","executionInfo":{"status":"ok","timestamp":1621753867336,"user_tz":-300,"elapsed":7,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"cb978376-6856-4bb4-fdb0-a06e275b9010"},"source":["out"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(7., grad_fn=<SumBackward0>)"]},"metadata":{"tags":[]},"execution_count":5},{"output_type":"execute_result","data":{"text/plain":["tensor(7., grad_fn=<SumBackward0>)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"idE7f5VpDqKp"},"source":["We know that the gradient of the preceding function is 2*x. Let's validate this using the built-in functions provided by PyTorch."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tkf9OSbGDhHn","executionInfo":{"status":"ok","timestamp":1621753968560,"user_tz":-300,"elapsed":17,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"4209b76e-0f51-48a6-bc43-ad6dda660bb3"},"source":["2*x.sum()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(6., grad_fn=<MulBackward0>)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"VsrA3ptlEmLc"},"source":["# The gradient of a value can be calculated by calling the backward() method to the value. In our case, we calculate the gradient – change in out (output) for a small change in x (input) – as follows:"]},{"cell_type":"code","metadata":{"id":"iG-yY8jREJxB","executionInfo":{"status":"ok","timestamp":1621754130764,"user_tz":-300,"elapsed":14,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["out.backward()"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X5U24pDBFb5z"},"source":["# We are now in a position to obtain the gradient of out with respect to x, as follows:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9JzfYq7RFCyO","executionInfo":{"status":"ok","timestamp":1621754264222,"user_tz":-300,"elapsed":375,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"7c07e129-3741-4d97-fe2d-1154827f0bd4"},"source":["x.grad"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 4., -2.],\n","        [ 2.,  2.]])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"VF8AkxVVGqm3"},"source":["Notice that the gradients obtained previously match with the intuitive gradient values (which are two times that of the value of x)."]},{"cell_type":"markdown","metadata":{"id":"ElxUzDD4GAp7"},"source":["# **Computing gradients for the same case that was present in Chain_rule.ipynb notebook in previous chapter**"]},{"cell_type":"code","metadata":{"id":"nsRH5PzEFggw","executionInfo":{"status":"ok","timestamp":1621754810850,"user_tz":-300,"elapsed":1402,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["x = np.array([[1,1]])\n","y = np.array([[0]])\n","x,y = [torch.tensor(i).float()for i in [x,y]]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"RYaLIClWHXu6","executionInfo":{"status":"ok","timestamp":1621754909854,"user_tz":-300,"elapsed":406,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["W = [\n","    np.array([[-0.0053, 0.3793],\n","              [-0.5820, -0.5204],\n","              [-0.2723, 0.1896]], dtype=np.float32).T, \n","    np.array([-0.0140, 0.5607, -0.0628], dtype=np.float32), \n","    np.array([[ 0.1528, -0.1745, -0.1135]], dtype=np.float32).T, \n","    np.array([-0.5516], dtype=np.float32)\n","]\n","W = [torch.tensor(i,requires_grad=True)for i in W]"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"S58vlepAIAp1","executionInfo":{"status":"ok","timestamp":1621755370443,"user_tz":-300,"elapsed":516,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["def feed_forward(inputs,outputs,weights):\n","    pre_hidden = torch.matmul(inputs,weights[0]+weights[1])\n","    hidden = 1/(1+torch.exp(-pre_hidden))\n","    out = torch.matmul(hidden, weights[2]) + weights[3]\n","    mean_squared_error = torch.mean(torch.square(out - outputs))\n","    return mean_squared_error"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mg-EvCC5JxdP","executionInfo":{"status":"ok","timestamp":1621755401396,"user_tz":-300,"elapsed":396,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"25dc643a-c0f7-4a0f-ad6b-02b50888a02b"},"source":["loss = feed_forward(x,y,W)\n","loss"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(0.3613, grad_fn=<MeanBackward0>)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"uEvKfkyjJ5D4","executionInfo":{"status":"ok","timestamp":1621755425812,"user_tz":-300,"elapsed":368,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["loss.backward()"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MNzu4rnkJ-eG","executionInfo":{"status":"ok","timestamp":1621755487478,"user_tz":-300,"elapsed":1817,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"10750a95-40c4-4a43-86dd-69cdffd1ac54"},"source":["print([w.grad for w in W])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[tensor([[-0.0446,  0.0524,  0.0337],\n","        [-0.0446,  0.0524,  0.0337]]), tensor([-0.0891,  0.1049,  0.0675]), tensor([[-0.7040],\n","        [-0.6068],\n","        [-0.5387]]), tensor([-1.2021])]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L2RGkv5QKNh1","executionInfo":{"status":"ok","timestamp":1621755609431,"user_tz":-300,"elapsed":852,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}}},"source":["updated_w = [w-w.grad for w in W]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nmdu7khPKrdI","executionInfo":{"status":"ok","timestamp":1621755617574,"user_tz":-300,"elapsed":581,"user":{"displayName":"Usama Amjad","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg7L11yS2Fc2bXwrAlwLL_Ih2_lSP1oQy-GZI9wGw=s64","userId":"17999911935826778950"}},"outputId":"1039a319-aaa1-44dc-c3c7-84d24e1a67e6"},"source":["updated_w"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[tensor([[ 0.0393, -0.6344, -0.3060],\n","         [ 0.4239, -0.5728,  0.1559]], grad_fn=<SubBackward0>),\n"," tensor([ 0.0751,  0.4558, -0.1303], grad_fn=<SubBackward0>),\n"," tensor([[0.8568],\n","         [0.4323],\n","         [0.4252]], grad_fn=<SubBackward0>),\n"," tensor([0.6505], grad_fn=<SubBackward0>)]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"CslqXPZ0KtyV"},"source":[""],"execution_count":null,"outputs":[]}]}